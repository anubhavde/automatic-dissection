{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anubhavde/multi-organ-ftu-segmentation?scriptVersionId=106534203\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# **HuBMAP + HPA - Hacking the Human Body**\n##### **Segment multi-organ functional tissue units**","metadata":{}},{"cell_type":"markdown","source":"### **Importing necessary modules & packages**","metadata":{}},{"cell_type":"code","source":"# Importing EfficientNet models with intermediate endpoints\nimport sys\nsys.path.append('../input/efficientnetv2-head-1x1-endpoint-v2/')\nsys.path.append('../input/efficientnetv2-head-1x1-endpoint-v2/efficientnetv2/')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:35.672544Z","iopub.execute_input":"2022-09-26T05:15:35.673552Z","iopub.status.idle":"2022-09-26T05:15:35.76727Z","shell.execute_reply.started":"2022-09-26T05:15:35.67341Z","shell.execute_reply":"2022-09-26T05:15:35.766589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom kaggle_datasets import KaggleDatasets\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n\nimport effnetv2_model\nimport re, os, io, time, pickle, math\nimport random, sys, cv2, gc, tifffile","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:35.769199Z","iopub.execute_input":"2022-09-26T05:15:35.769451Z","iopub.status.idle":"2022-09-26T05:15:41.664216Z","shell.execute_reply.started":"2022-09-26T05:15:35.769421Z","shell.execute_reply":"2022-09-26T05:15:41.663503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Seeding Random number generators**","metadata":{}},{"cell_type":"code","source":"def seed_all(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nSEED = 42\nseed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.665332Z","iopub.execute_input":"2022-09-26T05:15:41.665599Z","iopub.status.idle":"2022-09-26T05:15:41.66991Z","shell.execute_reply.started":"2022-09-26T05:15:41.665566Z","shell.execute_reply":"2022-09-26T05:15:41.669264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Threshold to classify a pixel as mask\nTHRESHOLD = 0.1\n\nDEBUG = False\nIS_TPU = True\n\n# Image dimensions\nIMG_SIZE = 640\nPATCH_SIZE = 640\nN_CHANNELS = 3\nN_PATCHES_PER_IMAGE = (IMG_SIZE // PATCH_SIZE) ** 2\n\nINPUT_SHAPE = (PATCH_SIZE, PATCH_SIZE, N_CHANNELS)\n\n# EfficientNet version\nEFN_SIZE = 'b8'\nLR_MAX = 0.02\nEPOCHS = 30\nMOMENTUM = 0.00\n\n# Batch size\nBATCH_SIZE = 64\n\n# Dataset Mean and Standard Deviation\nMEAN = np.load('/kaggle/input/hubmap-patched-tfrecords-300x300/MEAN.npy')\nSTD = np.load('/kaggle/input/hubmap-patched-tfrecords-300x300/STD.npy')\n\nprint(f'MEAN: {MEAN}, STD: {STD}')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.671392Z","iopub.execute_input":"2022-09-26T05:15:41.671864Z","iopub.status.idle":"2022-09-26T05:15:41.706219Z","shell.execute_reply.started":"2022-09-26T05:15:41.671822Z","shell.execute_reply":"2022-09-26T05:15:41.705489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Hardware Configuration**","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n     # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.708467Z","iopub.execute_input":"2022-09-26T05:15:41.708726Z","iopub.status.idle":"2022-09-26T05:15:41.71987Z","shell.execute_reply.started":"2022-09-26T05:15:41.708697Z","shell.execute_reply":"2022-09-26T05:15:41.718979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **FPN**","metadata":{}},{"cell_type":"code","source":"def FPN(xs, output_channels, last_layer, debug=False):\n    def _conv(x):\n        x = tf.keras.layers.ZeroPadding2D(padding=1)(x)\n        x = tf.keras.layers.Conv2D(output_channels * 2, 3, padding='SAME', kernel_initializer='he_normal', activation='relu')(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.ZeroPadding2D(padding=1)(x)\n        x = tf.keras.layers.Conv2D(output_channels, 3, padding='SAME', kernel_initializer='he_normal')(x)\n        x = tf.image.resize(x, size=target_size, method=tf.image.ResizeMethod.BILINEAR)\n        x = tf.nn.relu(x)\n        return x\n\n    target_size = last_layer.shape[1:3]\n    xs = tf.keras.layers.Concatenate()([_conv(x) for x in xs])\n    x = tf.keras.layers.Concatenate()([xs, last_layer])\n\n    if debug:\n        return x, xs\n    else:\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.7211Z","iopub.execute_input":"2022-09-26T05:15:41.721477Z","iopub.status.idle":"2022-09-26T05:15:41.729976Z","shell.execute_reply.started":"2022-09-26T05:15:41.721439Z","shell.execute_reply":"2022-09-26T05:15:41.728974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **ASPP**","metadata":{}},{"cell_type":"code","source":"def ASPP(x, mid_c=320, dilations=[1, 2, 3, 4], out_c=640, debug=False):\n    def _aspp_module(x, filters, kernel_size, padding, dilation, groups=1):\n        x = tf.keras.layers.ZeroPadding2D(padding=padding)(x)\n        x = tf.keras.layers.Conv2D(\n                filters=filters,\n                kernel_size=kernel_size,\n                dilation_rate=dilation,\n                groups=1 if IS_TPU else groups,\n                kernel_initializer='he_uniform',\n            )(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.nn.relu(x)\n        \n        return x\n    \n    x0 = tf.math.reduce_max(x, axis=(1,2), keepdims=True)\n    x0 = tf.keras.layers.Conv2D(filters=mid_c, kernel_size=1, strides=1, kernel_initializer='he_uniform', use_bias=False)(x0)\n    x0 = tf.keras.layers.BatchNormalization(gamma_initializer=tf.constant_initializer(value=0.25))(x0)\n    x0 = tf.nn.relu(x0)\n                                  \n                                  \n    xs = (\n        [_aspp_module(x, mid_c, 1, padding=0, dilation=1)] +\n        [_aspp_module(x, mid_c, 3, padding=d, dilation=d, groups=4) for d in dilations]\n    )\n    \n    x0= tf.image.resize(x0, size=xs[0].shape[1:3])\n    x = tf.keras.layers.Concatenate()([x0] + xs)\n    x = tf.keras.layers.Conv2D(filters=out_c, kernel_size=1, kernel_initializer='he_uniform', use_bias=False)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.nn.relu(x)\n                       \n    if debug:\n        return x, x0, xs\n    else:\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.73159Z","iopub.execute_input":"2022-09-26T05:15:41.731843Z","iopub.status.idle":"2022-09-26T05:15:41.745013Z","shell.execute_reply.started":"2022-09-26T05:15:41.731813Z","shell.execute_reply":"2022-09-26T05:15:41.744289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Upsample**","metadata":{}},{"cell_type":"code","source":"def PixelShuffle(x, upscale_factor=2):\n    _, w, h, c = x.shape\n    n = -1\n\n    c_out = c // upscale_factor ** 2\n    w_out = w * upscale_factor\n    h_out = h * upscale_factor\n\n    x = tf.reshape(x, [-1, upscale_factor, upscale_factor, w, h, c_out])\n    x = tf.transpose(x, [0, 3, 1, 4, 2, 5])\n    x = tf.reshape(x, [-1, w_out, h_out, c_out])\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.746022Z","iopub.execute_input":"2022-09-26T05:15:41.747211Z","iopub.status.idle":"2022-09-26T05:15:41.754626Z","shell.execute_reply.started":"2022-09-26T05:15:41.747186Z","shell.execute_reply":"2022-09-26T05:15:41.753947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspiration: https://www.tensorflow.org/tutorials/generative/pix2pix#build_an_input_pipeline_with_tfdata\ndef upsample(x, concat, target_filters, name, conv2dt_kernel_init_max, relu=True, dropout=0, debug=False):\n#     x = PixelShuffle(x)\n\n    filters = concat.shape[-1]\n    x_up = tf.keras.layers.Conv2DTranspose(\n            filters, # Number of Convolutional Filters\n            kernel_size=4, # Kernel Size\n            strides=2, # Kernel Steps\n            padding='SAME', # linear scaling\n            name=f'Conv2DTranspose_{name}', # Name of Layer\n            kernel_initializer='he_uniform',\n            use_bias=False,\n        )(x)\n    \n    concat = tf.keras.layers.BatchNormalization(\n        gamma_initializer=tf.constant_initializer(value=0.25),\n        name=f'BatchNormalization_{name}'\n    )(concat)\n    x = tf.keras.layers.Concatenate(name=f'Concatenate_{name}')([x_up, concat])\n    x = tf.nn.relu(x)\n    \n        \n    x = tf.keras.layers.Conv2D(target_filters, 3, padding='SAME', kernel_initializer='he_uniform', activation='relu', name=f'Conv2D_1_{name}')(x)\n    x = tf.keras.layers.Conv2D(target_filters, 3, padding='SAME', kernel_initializer='he_uniform', name=f'Conv2D_2_{name}')(x)\n    \n    if relu:\n        x = tf.nn.relu(x)\n    \n    x = tf.keras.layers.Dropout(dropout, name=f'Dropout_{name}')(x)\n\n    if debug:\n        return x, x_up, concat\n    else:\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.755873Z","iopub.execute_input":"2022-09-26T05:15:41.756124Z","iopub.status.idle":"2022-09-26T05:15:41.764882Z","shell.execute_reply.started":"2022-09-26T05:15:41.756092Z","shell.execute_reply":"2022-09-26T05:15:41.764095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model**","metadata":{}},{"cell_type":"code","source":"def get_model(dropout_decoder=0, dropout_cnn=0, file_path=None, lr=1e-3, eps=1e-7, clipnorm=5.0, wd_coef=1e-2, cnn_trainable=True):\n    with strategy.scope():\n        # EfficientNetV2 Backbone # \n        cnn = effnetv2_model.get_model(f'efficientnet-{EFN_SIZE}', include_top=False, weights=None, model_config={ 'conv_dropout': dropout_cnn })\n        cnn.trainable = cnn_trainable\n\n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.float32)\n        image_norm = tf.cast(image, tf.float32) / 255\n        image_norm = tf.keras.layers.experimental.preprocessing.Normalization(mean=MEAN, variance=STD, dtype=tf.float32)(image_norm)\n\n        embedding, up6, up5, up4, up3, up2, up1 = cnn(image_norm, with_endpoints=True)\n        print(f'embedding shape: {embedding.shape} up1 shape: {up1.shape}, up2 shape: {up2.shape}')\n        print(f'up3 shape: {up3.shape}, up4 shape: {up4.shape}, up5 shape: {up5.shape}, up6 shape: {up6.shape}')\n        \n        dec0 = ASPP(up2)\n        dec0 = tf.keras.layers.Dropout(0.50)(dec0)\n\n        dec1 = upsample(dec0, up3, up4.shape[-1] * 4, 'upsample1', 0.02, dropout=dropout_decoder)\n        dec2 = upsample(dec1, up4, up5.shape[-1] * 2, 'upsample2', 0.02, dropout=dropout_decoder)\n        dec3 = upsample(dec2, up5, up6.shape[-1] * 2, 'upsample3', 0.02)\n        dec4 = upsample(dec3, up6, 64, 'upsample4', 0.02)\n        \n        print(f'dec0 shape: {dec0.shape}, dec1 shape: {dec1.shape}, dec2 shape: {dec2.shape}, dec3 shape: {dec3.shape}, dec4 shape: {dec4.shape}')\n        \n        dec_fpn = FPN([dec0, dec1, dec2, dec3], 32, dec4)\n        \n        print(f'dec_fpn shape: {dec_fpn.shape}')\n        \n        # Head\n        x = tf.keras.layers.Dropout(0.10)(dec_fpn)\n        x = tf.keras.layers.Conv2D(\n            filters=1,\n            kernel_size=1,\n            padding='SAME',\n            kernel_initializer=tf.random_normal_initializer(0.00, 0.05),\n            activation='sigmoid',\n            name='Conv2D_3_head'\n        )(x)\n        output = tf.image.resize(x, size=[IMG_SIZE, IMG_SIZE], method=tf.image.ResizeMethod.BILINEAR)\n        \n        model = tf.keras.models.Model(inputs=image, outputs=output)\n\n        if file_path:\n            print('Loading pretrained weights...')\n            model.load_weights(file_path)\n            \n        model.trainable = False\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.766154Z","iopub.execute_input":"2022-09-26T05:15:41.766637Z","iopub.status.idle":"2022-09-26T05:15:41.780749Z","shell.execute_reply.started":"2022-09-26T05:15:41.766606Z","shell.execute_reply":"2022-09-26T05:15:41.779976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\nmodel = get_model(file_path='../input/hubmap-training-tf-tpu-efficientnet-b8-640640-p/model_0.h5')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:15:41.782086Z","iopub.execute_input":"2022-09-26T05:15:41.782643Z","iopub.status.idle":"2022-09-26T05:16:05.734366Z","shell.execute_reply.started":"2022-09-26T05:15:41.782572Z","shell.execute_reply":"2022-09-26T05:16:05.733584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:05.735799Z","iopub.execute_input":"2022-09-26T05:16:05.736071Z","iopub.status.idle":"2022-09-26T05:16:05.828526Z","shell.execute_reply.started":"2022-09-26T05:16:05.736038Z","shell.execute_reply":"2022-09-26T05:16:05.827827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:05.830274Z","iopub.execute_input":"2022-09-26T05:16:05.831493Z","iopub.status.idle":"2022-09-26T05:16:09.113733Z","shell.execute_reply.started":"2022-09-26T05:16:05.831463Z","shell.execute_reply":"2022-09-26T05:16:09.112675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Utility Funtions**","metadata":{}},{"cell_type":"code","source":"# Resized a tensor to the specified size\ndef resize_tensor(tensor, size=IMG_SIZE, dtype=np.uint8):\n    return cv2.resize(tensor, [size, size], interpolation=cv2.INTER_CUBIC).astype(dtype)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.117599Z","iopub.execute_input":"2022-09-26T05:16:09.118097Z","iopub.status.idle":"2022-09-26T05:16:09.123901Z","shell.execute_reply.started":"2022-09-26T05:16:09.118059Z","shell.execute_reply":"2022-09-26T05:16:09.123119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef get_mask(image_id):\n    row = train.loc[train['id'] == image_id].squeeze()\n    h, w = row[['img_height', 'img_width']]\n    mask = np.zeros(shape=[h * w], dtype=np.uint8)\n    s = row['rle'].split()\n    starts, lengths = [ np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2]) ]\n    starts -= 1\n    ends = starts + lengths\n    for lo, hi in zip(starts, ends):\n        mask[lo : hi] = 1\n        \n    mask = mask.reshape([h, w]).T\n        \n    mask = resize_tensor(mask)\n    \n    mask = np.expand_dims(mask, axis=2)\n        \n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.125266Z","iopub.execute_input":"2022-09-26T05:16:09.12594Z","iopub.status.idle":"2022-09-26T05:16:09.136396Z","shell.execute_reply.started":"2022-09-26T05:16:09.125907Z","shell.execute_reply":"2022-09-26T05:16:09.135773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reads an image and returns the image and original image size\ndef get_image(image_id, folder, negative=True):\n    image = tifffile.imread(f'/kaggle/input/hubmap-organ-segmentation/{folder}_images/{image_id}.tiff')\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    # Image Size\n    image_size, _, _ = image.shape\n    \n    # Reverse pixels to make tissue colored and background black\n    if negative:\n        image = image - image.min()\n        image = image / (image.max() - image.min())\n        image = image * 255\n        image = 255 - image.astype(np.uint8)\n        \n    # Resize\n    image = resize_tensor(image)\n    return image, image_size","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.137369Z","iopub.execute_input":"2022-09-26T05:16:09.138039Z","iopub.status.idle":"2022-09-26T05:16:09.147032Z","shell.execute_reply.started":"2022-09-26T05:16:09.137999Z","shell.execute_reply":"2022-09-26T05:16:09.14612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract patches from image\ndef extract_patches(image):\n    _, _, c = image.shape\n    image = tf.expand_dims(image, 0)\n    image_patches = tf.image.extract_patches(image, [1,PATCH_SIZE,PATCH_SIZE,1], [1, PATCH_SIZE, PATCH_SIZE, 1], [1, 1, 1, 1], padding='SAME')\n    image_patches = tf.reshape(image_patches, [N_PATCHES_PER_IMAGE, PATCH_SIZE, PATCH_SIZE, c])\n    image_patches = image_patches.numpy()\n\n    return image_patches","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.148004Z","iopub.execute_input":"2022-09-26T05:16:09.148615Z","iopub.status.idle":"2022-09-26T05:16:09.157354Z","shell.execute_reply.started":"2022-09-26T05:16:09.148585Z","shell.execute_reply":"2022-09-26T05:16:09.156613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode_less_memory(img):\n    # transpose image\n    pixels = img.T.flatten()\n    pixels[0], pixels[-1] = 0, 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.15846Z","iopub.execute_input":"2022-09-26T05:16:09.159271Z","iopub.status.idle":"2022-09-26T05:16:09.177776Z","shell.execute_reply.started":"2022-09-26T05:16:09.159225Z","shell.execute_reply":"2022-09-26T05:16:09.177108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Inference**","metadata":{}},{"cell_type":"code","source":"# training DataFrame\ntrain = pd.read_csv('/kaggle/input/hubmap-organ-segmentation/train.csv')\n# test DataFrame\ntest = pd.read_csv('/kaggle/input/hubmap-organ-segmentation/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.178756Z","iopub.execute_input":"2022-09-26T05:16:09.179015Z","iopub.status.idle":"2022-09-26T05:16:09.539298Z","shell.execute_reply.started":"2022-09-26T05:16:09.178984Z","shell.execute_reply":"2022-09-26T05:16:09.538377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reconstruct original image from patches\ndef merge_patches(patches):\n    image = np.zeros(shape=[IMG_SIZE, IMG_SIZE, patches.shape[-1]], dtype=patches.dtype)\n    s = int(N_PATCHES_PER_IMAGE ** 0.50)\n    for r in range(s):\n        for c in range(s):\n            start_x = r * PATCH_SIZE\n            end_x = (r + 1) * PATCH_SIZE\n            start_y = c * PATCH_SIZE\n            end_y = (c + 1) * PATCH_SIZE\n            image[start_x:end_x, start_y:end_y] = patches[r * s + c]\n            \n    return image","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.541284Z","iopub.execute_input":"2022-09-26T05:16:09.541809Z","iopub.status.idle":"2022-09-26T05:16:09.549541Z","shell.execute_reply.started":"2022-09-26T05:16:09.541771Z","shell.execute_reply":"2022-09-26T05:16:09.548809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Test**","metadata":{}},{"cell_type":"code","source":"# verify the trained weights are correctly loaded on 10 predictions\ntest_rows = []\nN = 10\n\nfor row_idx, row in tqdm(train[:N].iterrows(), total=N):\n    # preprocess image\n    image, image_size = get_image(row['id'], 'train')\n    image_patches = extract_patches(image)\n    \n    # prediction\n    mask_patches_pred = model.predict(image_patches)\n    mask_pred = merge_patches(mask_patches_pred)\n    mask_pred_resized = resize_tensor(mask_pred, size=image_size, dtype=np.float32)\n    \n    fig, axes = plt.subplots(1,2, figsize=(8,4))\n    axes[0].imshow(mask_pred_resized)\n    axes[1].imshow(image)\n    plt.show()\n        \n    mask_binary = (mask_pred_resized > THRESHOLD).astype(np.int8)\n    test_rows.append({\n        'id': row['id'],\n        'rle': rle_encode_less_memory(mask_binary)\n    })","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:09.550946Z","iopub.execute_input":"2022-09-26T05:16:09.551396Z","iopub.status.idle":"2022-09-26T05:16:44.007269Z","shell.execute_reply.started":"2022-09-26T05:16:09.551363Z","shell.execute_reply":"2022-09-26T05:16:44.00632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Inference Loop**","metadata":{}},{"cell_type":"code","source":"# store predictions in list of dictionaries\ntest_rows = []\nfor row_idx, row in tqdm(test.iterrows(), total=len(test)):\n    # preprocess image\n    image, image_size = get_image(row['id'], 'test')\n    image_patches = extract_patches(image)\n    \n    # prediction\n    mask_patches_pred = model.predict(image_patches)\n    # merge patches & resize mask to original size\n    mask_pred = merge_patches(mask_patches_pred)\n    mask_pred_resized = resize_tensor(mask_pred, size=image_size, dtype=np.float32)\n    \n    if row_idx == 0:\n        fig, axes = plt.subplots(1,2, figsize=(8,4))\n        axes[0].imshow(mask_pred_resized)\n        axes[1].imshow(image)\n        plt.show()\n        \n    # resize and binarize mask\n    mask_binary = (mask_pred_resized > THRESHOLD).astype(np.int8)\n    test_rows.append({\n        'id': row['id'],\n        'rle': rle_encode_less_memory(mask_binary)\n    })","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:44.008949Z","iopub.execute_input":"2022-09-26T05:16:44.009529Z","iopub.status.idle":"2022-09-26T05:16:45.343261Z","shell.execute_reply.started":"2022-09-26T05:16:44.009473Z","shell.execute_reply":"2022-09-26T05:16:45.342427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Submission**","metadata":{}},{"cell_type":"code","source":"test_df = pd.DataFrame(test_rows)\ntest_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T05:16:45.344729Z","iopub.execute_input":"2022-09-26T05:16:45.344997Z","iopub.status.idle":"2022-09-26T05:16:45.355287Z","shell.execute_reply.started":"2022-09-26T05:16:45.344962Z","shell.execute_reply":"2022-09-26T05:16:45.354597Z"},"trusted":true},"execution_count":null,"outputs":[]}]}